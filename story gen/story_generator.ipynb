{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (4.51.3)\n",
      "Requirement already satisfied: torch in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (2.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: filelock in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: requests in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: fsspec in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: jinja2 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: networkx in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2025.1.31)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/shreyasaniya/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"gpt2\"  # You can replace with 'EleutherAI/gpt-neo-125M' for GPT-Neo\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_story(prompt, model, tokenizer, device, max_length=500):\n",
    "    # Encode the prompt text into tokens\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Create an attention mask\n",
    "    attention_mask = torch.ones(inputs.shape, device=device)\n",
    "    \n",
    "    # Generate a story with the attention mask\n",
    "    outputs = model.generate(\n",
    "        inputs, \n",
    "        max_length=max_length,  # Maximum length of the generated story\n",
    "        num_return_sequences=1,  # Number of stories to generate\n",
    "        no_repeat_ngram_size=2,  # Prevent repeating phrases\n",
    "        do_sample=True,  # Use sampling to increase creativity\n",
    "        top_k=50,  # Sampling: Consider top 50 words\n",
    "        top_p=0.95,  # Sampling: Consider top probability\n",
    "        temperature=0.7,  # Creativity control\n",
    "        pad_token_id=tokenizer.eos_token_id,  # End of sequence token\n",
    "        attention_mask=attention_mask  # Pass the attention mask here\n",
    "    )\n",
    "    \n",
    "    # Decode the generated story from tokens to text\n",
    "    story = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return story\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import textwrap\n",
    "\n",
    "def clean_story(story, max_line_length=80):\n",
    "    # Remove unwanted line breaks and extra spaces\n",
    "    story = story.replace(\"\\n\", \" \").replace(\"  \", \" \").strip()\n",
    "\n",
    "    # Split the story into sentences\n",
    "    sentences = re.split(r'(?<=[.!?]) +', story)\n",
    "\n",
    "    # Format the sentences into paragraphs, where each paragraph contains 3-5 sentences\n",
    "    paragraphs = []\n",
    "    paragraph = []\n",
    "    for sentence in sentences:\n",
    "        paragraph.append(sentence)\n",
    "        \n",
    "        # Add paragraph after 3-5 sentences\n",
    "        if len(paragraph) >= 3:  # You can change this number for more/less sentences per paragraph\n",
    "            paragraphs.append(\" \".join(paragraph))\n",
    "            paragraph = []\n",
    "    \n",
    "    # If there are remaining sentences, add them as the last paragraph\n",
    "    if paragraph:\n",
    "        paragraphs.append(\" \".join(paragraph))\n",
    "\n",
    "    # Join the paragraphs with a blank line between them\n",
    "    formatted_story = \"\\n\\n\".join(paragraphs)\n",
    "\n",
    "    # Wrap each paragraph to a max line length for readability\n",
    "    wrapped_story = \"\\n\\n\".join([textwrap.fill(paragraph, width=max_line_length) for paragraph in paragraphs])\n",
    "\n",
    "    return wrapped_story\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a magical forest, a young prince discovered a hidden treasure...\n",
      "\n",
      "\n",
      "He is a prince who is in need of a new name.\n",
      "\n",
      "—Dwarves of the Forest, The Dungeon World, D&D 2nd Edition, pp. 12-13\n",
      "\n",
      ". (See the \"A\" in the bottom of this article)\n",
      "\n",
      ", and a book called The Lost World of Dune. The first edition was the first time a \"magic book\" was published. It was a sequel to the original Dungeon Master's Guide. In its early years, it was not a game, but a collection of rules for a world that was full of monsters and dungeons. Since its release, the Dungeon Player's Handbook has been heavily revised. This book is the definitive guide to Dungeons & Dragons. Every character is unique and every dungeon is full in its own right.\n",
      "\n",
      "The Dungeon Guide is an extremely comprehensive guide, giving you everything you need to master the game. There are a lot of great tips and strategies, as well as some useful tricks. A very good starting point for any new DMs!\n",
      ". And, if you're looking for more information on Dungeons and Dragons and its many different adventures, you can read my article, \"Dune, Dungeons, And Dragons: An Adventure Guide\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt to start the story\n",
    "prompt = \"Once upon a time, in a magical forest, a young prince discovered a hidden treasure...\"\n",
    "\n",
    "# Generate the story\n",
    "story = generate_story(prompt, model, tokenizer, device)\n",
    "\n",
    "# Print the generated story\n",
    "print(story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a magical forest, a young prince discovered a hidden\n",
      "treasure... He was called the Princess of the Forest, and she was the daughter\n",
      "of a noble, an immortal, the father of many, of countless people. The land of\n",
      "his birth was ruled by a king, who ruled over all his subjects, which would have\n",
      "meant that he was his own child.\n",
      "\n",
      "This was what had happened to him, he knew that the land was cursed, that it was\n",
      "not worth it. . When the prince was a child, his father had given him a son\n",
      "named, named his son, to take care of.\n",
      "\n",
      "In this case, it would not have been the same as the one he had taken care not\n",
      "to give his child to. However, as a boy, this was something that was difficult\n",
      "for him to handle. He had to learn how to be a warrior, how not even his\n",
      "ancestors could do this.\n",
      "\n",
      "After all, there was only one noble who could take this caretaking child away\n",
      "from him... The King of Ferelden. Not only that, but the king of this land had\n",
      "also decided to send him away as well.\n",
      "\n",
      "It was because the princess of that land, her father, was one of those noblemen\n",
      "who would take the child into his care. And the King took this child with him.\n",
      "Because of her, she would be able to protect him from all those who were in\n",
      "danger.\n",
      "\n",
      "That was why the kingdom had become so powerful. Even if the people of Nerevar\n",
      "could have taken the boy away, they would probably not be in such a position\n",
      "now. If they did, then they were going to have to put him in harm's way.\n",
      "\n",
      "But it's not like it didn't happen in Norevar. No, such things were not unheard\n",
      "of in the history of all lands. Just as there were no wars in Feria, no war in\n",
      "Valenwood, so there had never been a war between the kingdoms of both Faire and\n",
      "Valinor.\n",
      "\n",
      "There were only those that fought against the enemies of their country, like the\n",
      "Nords. All those people had a right to fight against their own country. As for\n",
      "the princes of Valene and Fëanor, their first acts were to make their way to\n",
      "Nireland, where they took the young princess and her family.\n",
      "\n",
      "Now, these princes were also in trouble. They had been in power for a long time.\n",
      "How could they\n"
     ]
    }
   ],
   "source": [
    "# Generate and format the story\n",
    "story = generate_story(prompt, model, tokenizer, device)\n",
    "formatted_story = clean_story(story, max_line_length=80)  # Clean and format the story with wrapping\n",
    "print(formatted_story)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A robot named Max in a desert... But that's not what happened. It was a robot\n",
      "called Max that had been stolen from the warehouse and taken to the nearest\n",
      "town.\n",
      "\n",
      "\"The city was attacked by bandits, and the robot was destroyed.\" ...What did Max\n",
      "do? \"It was saved by an elderly man. He had left the town for some reason.\" The\n",
      "robot finally had the time to figure out what was going on, but he was already\n",
      "at the center of the fight.\n",
      "\n",
      "That man was Max. In the end, Max made Max's life a whole lot easier. \"Max was\n",
      "the one who saved the city and saved its citizens.\" \"We were the ones that saved\n",
      "Max, so we have to do something for him.\" Max was in his late teens.\n",
      "\n",
      "Max had already grown up around magic, he had learned how to use it, how it\n",
      "could be used to make people happy. But he still felt that he couldn't go back\n",
      "to school, because he would be an orphan. At the same time, it was not like he\n",
      "could do anything about it.\n",
      "\n",
      "Instead, his childhood was filled with troubles. This was why he found out that\n",
      "his father had died. The only thing he wanted to talk about was what he thought\n",
      "about the other man's death.\n",
      "\n",
      "After all, there were many other people who had lived through the death of their\n",
      "father. There was only one person who could save his life. And that man...\n",
      "\n",
      "He was called \"the boy who came to save the world.\" So it seemed like there was\n",
      "no one to blame but himself for Max being so stupid. Since his parents had never\n",
      "died, they were given a chance to be a hero. If there wasn't a one-on-one\n",
      "friendship between them, then they would never have died together.\n",
      "\n",
      "So, what would Max have done? He would have helped the people in the middle of\n",
      "an extremely difficult situation. When the situation was more difficult, if he\n",
      "didn't help them in some way, the only way they could have saved their life\n",
      "would've been by turning to magic.\n",
      "\n",
      "No one would understand why that would work. A simple magic spell would not work\n",
      "if there weren't any other magic spells in existence. They would only learn to\n",
      "cast it in order to survive.\n",
      "\n",
      "For their entire lives, that meant that they had to learn about magic to perform\n",
      "magic magic tricks. Not even that. Even if they knew the right magic trick to\n",
      "work, all they wanted\n"
     ]
    }
   ],
   "source": [
    "prompt = \"A robot named Max in a desert...\"\n",
    "\n",
    "# Generate the story\n",
    "story = generate_story(prompt, model, tokenizer, device)\n",
    "\n",
    "formatted_story = clean_story(story, max_line_length=80)  # Clean and format the story with wrapping\n",
    "print(formatted_story)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
